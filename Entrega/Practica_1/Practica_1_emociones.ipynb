{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este código está escrito en Python y utiliza la biblioteca OpenCV (importada como `cv`) para realizar operaciones de procesamiento de imágenes y video. \n",
    "\n",
    "Primero, se define una función `escala` que toma una imagen y un factor de escala como entrada, y devuelve la imagen redimensionada. La imagen se redimensiona utilizando la función `cv.resize`, que cambia el tamaño de la imagen a las dimensiones especificadas.\n",
    "\n",
    "Luego, se inicializa un clasificador de cascada para la detección de rostros (`haarcascade_frontalface_alt.xml`) y se abre la cámara del dispositivo para capturar video en tiempo real.\n",
    "\n",
    "El código entra en un bucle infinito donde lee cada fotograma del video, lo convierte a escala de grises y luego utiliza el clasificador de cascada para detectar rostros en el fotograma. Para cada rostro detectado, se extrae la región del rostro del fotograma, se redimensiona a un tamaño fijo de 100x100 píxeles y luego se muestra en una ventana. Además, cada imagen de rostro redimensionada se guarda en el disco con un nombre de archivo que incluye un contador incremental.\n",
    "\n",
    "El bucle continúa hasta que se presiona la tecla 'Esc' (representada por el número 27). Al final, se libera el objeto de captura de video y se cierran todas las ventanas de imagen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import math\n",
    "def escala(imx, escala):\n",
    "    width = int(imx.shape[1] * escala / 100)\n",
    "    height = int(imx.shape[0] * escala / 100)\n",
    "    size = (width, height)\n",
    "    im = cv.resize(imx, size, interpolation=cv.INTER_AREA)\n",
    "    return im\n",
    "face = cv.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
    "cap = cv.VideoCapture(0)\n",
    "i = 0\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    faces = face.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x, y, w, h) in faces:\n",
    "        #frame = cv.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        frame2 = frame[y:y + h, x:x + w]\n",
    "        #frame2 = escala(frame2,50)\n",
    "        frame2 = cv.resize(frame2, (100,100), interpolation=cv.INTER_AREA)\n",
    "        cv.imshow('frame', frame2)\n",
    "        cv.imwrite(\"E:/bd/dante/emociones/Triste/Triste\" + str(i) + \".png\", frame2)\n",
    "    cv.imshow('faces', frame)\n",
    "    i = i + 1\n",
    "    k = cv.waitKey(1)\n",
    "    if k == 27:\n",
    "        break\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LBPH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este código en Python utiliza la biblioteca OpenCV para entrenar un modelo de reconocimiento facial utilizando el algoritmo LBPH (Local Binary Patterns Histograms).\n",
    "\n",
    "Primero, se establece la ruta al conjunto de datos de imágenes de caras con `dataSet = 'bd\\personas'`. Luego, se utiliza `os.listdir(dataSet)` para obtener una lista de todos los archivos en ese directorio, que se asume que son imágenes de caras. Esta lista se imprime en la consola.\n",
    "\n",
    "Después, se inicializan tres listas vacías: [`labels`](command:_github.copilot.openSymbolInFile?%5B%22c%3A%2FUsers%2Fdante%2FAppData%2FLocal%2FPrograms%2FPython%2FPython312%2FLib%2Fsite-packages%2Fcv2%2F__init__.pyi%22%2C%22labels%22%5D \"c:/Users/dante/AppData/Local/Programs/Python/Python312/Lib/site-packages/cv2/__init__.pyi\"), `facesData` y `label`. [`labels`](command:_github.copilot.openSymbolInFile?%5B%22c%3A%2FUsers%2Fdante%2FAppData%2FLocal%2FPrograms%2FPython%2FPython312%2FLib%2Fsite-packages%2Fcv2%2F__init__.pyi%22%2C%22labels%22%5D \"c:/Users/dante/AppData/Local/Programs/Python/Python312/Lib/site-packages/cv2/__init__.pyi\") y `facesData` se llenarán con los datos de las imágenes y sus respectivas etiquetas. `label` es un contador que se incrementará para cada cara en el conjunto de datos.\n",
    "\n",
    "El código luego entra en un bucle for que recorre cada cara en la lista de caras. Para cada cara, crea una ruta al archivo de la imagen, luego abre esa imagen y la añade a la lista `facesData`. También añade la etiqueta actual a la lista [`labels`](command:_github.copilot.openSymbolInFile?%5B%22c%3A%2FUsers%2Fdante%2FAppData%2FLocal%2FPrograms%2FPython%2FPython312%2FLib%2Fsite-packages%2Fcv2%2F__init__.pyi%22%2C%22labels%22%5D \"c:/Users/dante/AppData/Local/Programs/Python/Python312/Lib/site-packages/cv2/__init__.pyi\"). Luego incrementa la etiqueta.\n",
    "\n",
    "Finalmente, el código crea un objeto `LBPHFaceRecognizer` utilizando `cv.face.LBPHFaceRecognizer_create()`. Entrena este reconocedor con los datos de las caras y las etiquetas utilizando `faceRecognizer.train(facesData, np.array(labels))`. Luego guarda este reconocedor entrenado en un archivo llamado 'carasLBPHFace.xml' para su uso futuro.\n",
    "\n",
    "El algoritmo LBPH es un método popular para el reconocimiento facial que puede ser más eficiente y preciso que otros métodos para ciertos conjuntos de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv \n",
    "import numpy as np \n",
    "import os\n",
    "\n",
    "dataSet = \"E:/bd/emociones\"\n",
    "faces  = os.listdir(dataSet)\n",
    "print(faces)\n",
    "\n",
    "labels = []\n",
    "facesData = []\n",
    "label = 0 \n",
    "for face in faces:\n",
    "    facePath = dataSet+'/'+face\n",
    "    for faceName in os.listdir(facePath):\n",
    "        labels.append(label)\n",
    "        facesData.append(cv.imread(facePath+'/'+faceName,0))\n",
    "    label = label + 1\n",
    "#print(np.count_nonzero(np.array(labels)==0)) \n",
    "faceRecognizer = cv.face.LBPHFaceRecognizer_create()\n",
    "faceRecognizer.train(facesData, np.array(labels))\n",
    "faceRecognizer.write('emocionesLBPHFace.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este código es un ejemplo de reconocimiento facial utilizando la biblioteca OpenCV en Python. Aquí está lo que hace cada parte del código:\n",
    "\n",
    "1. Importa las bibliotecas necesarias: `cv2` para el procesamiento de imágenes y `os` para las operaciones del sistema operativo. Sin embargo, parece que `os` no se utiliza en este código.\n",
    "\n",
    "2. Crea un objeto `faceRecognizer` utilizando el método `LBPHFaceRecognizer_create()`. Este objeto se utiliza para reconocer caras en las imágenes.\n",
    "\n",
    "3. Lee un archivo XML que contiene el modelo de reconocimiento facial entrenado.\n",
    "\n",
    "4. Abre la cámara del dispositivo (indicado por el `0` en `cv.VideoCapture(0)`) para capturar video en tiempo real.\n",
    "\n",
    "5. Carga el clasificador de rostros Haar Cascade desde un archivo XML.\n",
    "\n",
    "6. Entra en un bucle infinito donde captura cada frame del video, lo convierte a escala de grises y detecta rostros en él.\n",
    "\n",
    "7. Para cada rostro detectado, se extrae la región de interés, se redimensiona a un tamaño estándar de 100x100 píxeles y se pasa al reconocedor de caras para obtener una predicción.\n",
    "\n",
    "8. La predicción y la confianza se dibujan en el frame original. Si la confianza es menor que 70, se considera que el rostro es reconocido y se dibuja un rectángulo verde alrededor del rostro. Si no, se considera desconocido y se dibuja un rectángulo rojo.\n",
    "\n",
    "9. Muestra el frame con las anotaciones en una ventana.\n",
    "\n",
    "10. Si se presiona la tecla `ESC` (27 en código ASCII), se rompe el bucle.\n",
    "\n",
    "11. Al final, libera el objeto de captura de video y cierra todas las ventanas de OpenCV.\n",
    "\n",
    "El error \"cv2 no está definido\" sugiere que estás intentando utilizar la biblioteca `cv2` pero la has importado como `cv`. Deberías cambiar todas las referencias de `cv2` a `cv` en tu código. Además, parece que la variable [`faces`](command:_github.copilot.openSymbolInFile?%5B%22c%3A%2FUsers%2Fdante%2FAppData%2FLocal%2FPrograms%2FPython%2FPython312%2FLib%2Fsite-packages%2Fcv2%2F__init__.pyi%22%2C%22faces%22%5D \"c:/Users/dante/AppData/Local/Programs/Python/Python312/Lib/site-packages/cv2/__init__.pyi\") no está definida en este fragmento de código. Necesitarías definirlo o importarlo de algún lugar antes de usarlo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
