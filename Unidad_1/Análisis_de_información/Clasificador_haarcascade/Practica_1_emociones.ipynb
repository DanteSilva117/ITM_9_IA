{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este código está escrito en Python y utiliza la biblioteca OpenCV (importada como `cv`) para realizar operaciones de procesamiento de imágenes y video. \n",
    "\n",
    "Primero, se define una función `escala` que toma una imagen y un factor de escala como entrada, y devuelve la imagen redimensionada. La imagen se redimensiona utilizando la función `cv.resize`, que cambia el tamaño de la imagen a las dimensiones especificadas.\n",
    "\n",
    "Luego, se inicializa un clasificador de cascada para la detección de rostros (`haarcascade_frontalface_alt.xml`) y se abre la cámara del dispositivo para capturar video en tiempo real.\n",
    "\n",
    "El código entra en un bucle infinito donde lee cada fotograma del video, lo convierte a escala de grises y luego utiliza el clasificador de cascada para detectar rostros en el fotograma. Para cada rostro detectado, se extrae la región del rostro del fotograma, se redimensiona a un tamaño fijo de 100x100 píxeles y luego se muestra en una ventana. Además, cada imagen de rostro redimensionada se guarda en el disco con un nombre de archivo que incluye un contador incremental.\n",
    "\n",
    "El bucle continúa hasta que se presiona la tecla 'Esc' (representada por el número 27). Al final, se libera el objeto de captura de video y se cierran todas las ventanas de imagen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import math\n",
    "def escala(imx, escala):\n",
    "    width = int(imx.shape[1] * escala / 100)\n",
    "    height = int(imx.shape[0] * escala / 100)\n",
    "    size = (width, height)\n",
    "    im = cv.resize(imx, size, interpolation=cv.INTER_AREA)\n",
    "    return im\n",
    "face = cv.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
    "cap = cv.VideoCapture(0)\n",
    "i = 0\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    faces = face.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x, y, w, h) in faces:\n",
    "        #frame = cv.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        frame2 = frame[y:y + h, x:x + w]\n",
    "        #frame2 = escala(frame2,50)\n",
    "        frame2 = cv.resize(frame2, (100,100), interpolation=cv.INTER_AREA)\n",
    "        cv.imshow('frame', frame2)\n",
    "        cv.imwrite(\"E:/bd/dante/emociones/Triste/Triste\" + str(i) + \".png\", frame2)\n",
    "    cv.imshow('faces', frame)\n",
    "    i = i + 1\n",
    "    k = cv.waitKey(1)\n",
    "    if k == 27:\n",
    "        break\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eigenface "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este código está utilizando la biblioteca OpenCV (importada como `cv`) para el reconocimiento facial. Primero, importa las bibliotecas necesarias: OpenCV, numpy y os.\n",
    "\n",
    "El código establece una ruta a un conjunto de datos de imágenes de caras con `dataSet = 'bd\\personas'`. Luego, utiliza `os.listdir(dataSet)` para obtener una lista de todos los archivos en ese directorio, que se asume que son imágenes de caras. Imprime esta lista de caras.\n",
    "\n",
    "Después, inicializa tres listas vacías: [`labels`](command:_github.copilot.openSymbolInFile?%5B%22c%3A%2FUsers%2Fdante%2FAppData%2FLocal%2FPrograms%2FPython%2FPython312%2FLib%2Fsite-packages%2Fcv2%2F__init__.pyi%22%2C%22labels%22%5D \"c:/Users/dante/AppData/Local/Programs/Python/Python312/Lib/site-packages/cv2/__init__.pyi\"), `facesData`, y `label`. [`labels`](command:_github.copilot.openSymbolInFile?%5B%22c%3A%2FUsers%2Fdante%2FAppData%2FLocal%2FPrograms%2FPython%2FPython312%2FLib%2Fsite-packages%2Fcv2%2F__init__.pyi%22%2C%22labels%22%5D \"c:/Users/dante/AppData/Local/Programs/Python/Python312/Lib/site-packages/cv2/__init__.pyi\") y `facesData` se llenarán con los datos de las imágenes y sus respectivas etiquetas. `label` es un contador que se incrementará para cada cara en el conjunto de datos.\n",
    "\n",
    "El código luego entra en un bucle for que recorre cada cara en la lista de caras. Para cada cara, crea una ruta al archivo de la imagen, luego abre esa imagen y la añade a la lista `facesData`. También añade la etiqueta actual a la lista [`labels`](command:_github.copilot.openSymbolInFile?%5B%22c%3A%2FUsers%2Fdante%2FAppData%2FLocal%2FPrograms%2FPython%2FPython312%2FLib%2Fsite-packages%2Fcv2%2F__init__.pyi%22%2C%22labels%22%5D \"c:/Users/dante/AppData/Local/Programs/Python/Python312/Lib/site-packages/cv2/__init__.pyi\"). Luego incrementa la etiqueta.\n",
    "\n",
    "Después de procesar todas las caras, imprime el número de etiquetas que son 0 utilizando [`np.count_nonzero(np.array(labels)==0)`](command:_github.copilot.openSymbolInFile?%5B%22c%3A%2FUsers%2Fdante%2FAppData%2FLocal%2FPrograms%2FPython%2FPython312%2FLib%2Fsite-packages%2Fnumpy%2Fcore%2Fnumeric.py%22%2C%22np.count_nonzero(np.array(labels)%3D%3D0)%22%5D \"c:/Users/dante/AppData/Local/Programs/Python/Python312/Lib/site-packages/numpy/core/numeric.py\"). Esto podría ser útil para saber cuántas imágenes pertenecen a la primera categoría.\n",
    "\n",
    "Finalmente, el código crea un objeto `EigenFaceRecognizer` utilizando `cv.face.EigenFaceRecognizer_create()`. Entrena este reconocedor con los datos de las caras y las etiquetas utilizando `faceRecognizer.train(facesData, np.array(labels))`. Luego guarda este reconocedor entrenado en un archivo llamado 'carasEigenface.xml' para su uso futuro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv \n",
    "import numpy as np \n",
    "import os\n",
    "\n",
    "dataSet = \"E:/bd/emocionesv2\"\n",
    "faces  = os.listdir(dataSet)\n",
    "print(faces)\n",
    "\n",
    "labels = []\n",
    "facesData = []\n",
    "label = 0\n",
    "for face in faces:\n",
    "    facePath = dataSet+'\\\\'+face\n",
    "    for faceName in os.listdir(facePath):\n",
    "        labels.append(label)\n",
    "        facesData.append(cv.imread(facePath+'/'+faceName,0))\n",
    "    label = label + 1\n",
    "print(np.count_nonzero(np.array(labels)==0))\n",
    "\n",
    "faceRecognizer = cv.face.EigenFaceRecognizer_create()\n",
    "faceRecognizer.train(facesData, np.array(labels))\n",
    "faceRecognizer.write('emocionesEigenface.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este código en Python utiliza la biblioteca OpenCV (importada como `cv`) para detectar y reconocer rostros en tiempo real a través de la cámara del dispositivo.\n",
    "\n",
    "La función `detectar_rostros` primero define la ruta del conjunto de datos que contiene las imágenes de las caras en la variable `dataSet`. Luego, se obtiene una lista de todos los archivos en ese directorio utilizando `os.listdir(dataSet)` y se imprime.\n",
    "\n",
    "Se crea un objeto `EigenFaceRecognizer` utilizando `cv.face.EigenFaceRecognizer_create()`. Este objeto se utiliza para leer un modelo previamente entrenado de reconocimiento de rostros desde el archivo 'carasEigenface.xml'.\n",
    "\n",
    "Luego, se abre la cámara del dispositivo para capturar video en tiempo real y se inicializa un clasificador de cascada para la detección de rostros (`haarcascade_frontalface_alt.xml`).\n",
    "\n",
    "El código entra en un bucle infinito donde lee cada fotograma del video, lo convierte a escala de grises y luego utiliza el clasificador de cascada para detectar rostros en el fotograma. Para cada rostro detectado, se extrae la región del rostro del fotograma, se redimensiona a un tamaño fijo de 100x100 píxeles y luego se utiliza el reconocedor de rostros para predecir a quién pertenece el rostro.\n",
    "\n",
    "Si el resultado de la predicción tiene una confianza mayor a 2800, se considera que el rostro ha sido reconocido y se dibuja un rectángulo verde alrededor del rostro en el fotograma, y se coloca el nombre de la persona reconocida encima del rectángulo. Si la confianza es menor a 2800, se considera que el rostro es desconocido y se dibuja un rectángulo rojo alrededor del rostro, y se coloca la palabra 'Desconocido' encima del rectángulo.\n",
    "\n",
    "El bucle continúa hasta que se presiona la tecla 'Esc' (representada por el número 27). Al final, se libera el objeto de captura de video y se cierran todas las ventanas de imagen abiertas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import os\n",
    "\n",
    "def detectar_rostros():\n",
    "\n",
    "    dataSet = \"E:/bd/emocionesv2\"\n",
    "    faces = os.listdir(dataSet)\n",
    "    print(faces)\n",
    "\n",
    "    faceRecognizer = cv.face.EigenFaceRecognizer_create()\n",
    "    faceRecognizer.read('emocionesEigenface.xml')\n",
    "\n",
    "    cap = cv.VideoCapture(0)\n",
    "    rostro = cv.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if ret == False:\n",
    "            break\n",
    "        gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "        cpGray = gray.copy()\n",
    "        rostros = rostro.detectMultiScale(gray, 1.3, 3)\n",
    "        for(x, y, w, h) in rostros:\n",
    "            frame2 = cpGray[y:y+h, x:x+w]\n",
    "            frame2 = cv.resize(frame2,  (100,100), interpolation=cv.INTER_CUBIC)\n",
    "            result = faceRecognizer.predict(frame2)\n",
    "            cv.putText(frame, '{}'.format(result), (x,y-20), 1,3.3, (255,255,0), 1, cv.LINE_AA)\n",
    "            if result[1] > 2800:\n",
    "                cv.putText(frame, '{}'.format(faces[result[0]]), (x,y-25), 2, 1.1, (0,255,0), 1, cv.LINE_AA)\n",
    "                cv.rectangle(frame, (x,y), (x+w,y+h), (0,255,0), 2)\n",
    "            else:\n",
    "                cv.putText(frame, 'Desconocido', (x,y-20), 2, 0.8, (0,0,255), 1, cv.LINE_AA)\n",
    "                cv.rectangle(frame, (x,y), (x+w,y+h), (0,0,255), 2)\n",
    "        cv.imshow('frame', frame)\n",
    "        k = cv.waitKey(1)\n",
    "        if k == 27:\n",
    "            break\n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()\n",
    "\n",
    "detectar_rostros()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
