{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/eAlcaraz85/vpcurso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este código está escrito en Python y utiliza la biblioteca OpenCV (importada como `cv`) para realizar operaciones de procesamiento de imágenes y video. \n",
    "\n",
    "Primero, se define una función `escala` que toma una imagen y un factor de escala como entrada, y devuelve la imagen redimensionada. La imagen se redimensiona utilizando la función `cv.resize`, que cambia el tamaño de la imagen a las dimensiones especificadas.\n",
    "\n",
    "Luego, se inicializa un clasificador de cascada para la detección de rostros (`haarcascade_frontalface_alt.xml`) y se abre la cámara del dispositivo para capturar video en tiempo real.\n",
    "\n",
    "El código entra en un bucle infinito donde lee cada fotograma del video, lo convierte a escala de grises y luego utiliza el clasificador de cascada para detectar rostros en el fotograma. Para cada rostro detectado, se extrae la región del rostro del fotograma, se redimensiona a un tamaño fijo de 100x100 píxeles y luego se muestra en una ventana. Además, cada imagen de rostro redimensionada se guarda en el disco con un nombre de archivo que incluye un contador incremental.\n",
    "\n",
    "El bucle continúa hasta que se presiona la tecla 'Esc' (representada por el número 27). Al final, se libera el objeto de captura de video y se cierran todas las ventanas de imagen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m ret, frame \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m     15\u001b[0m gray \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mcvtColor(frame, cv\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[1;32m---> 16\u001b[0m faces \u001b[38;5;241m=\u001b[39m \u001b[43mface\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetectMultiScale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (x, y, w, h) \u001b[38;5;129;01min\u001b[39;00m faces:\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;66;03m#frame = cv.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     frame2 \u001b[38;5;241m=\u001b[39m frame[y:y \u001b[38;5;241m+\u001b[39m h, x:x \u001b[38;5;241m+\u001b[39m w]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import math\n",
    "def escala(imx, escala):\n",
    "    width = int(imx.shape[1] * escala / 100)\n",
    "    height = int(imx.shape[0] * escala / 100)\n",
    "    size = (width, height)\n",
    "    im = cv.resize(imx, size, interpolation=cv.INTER_AREA)\n",
    "    return im\n",
    "face = cv.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
    "cap = cv.VideoCapture(0)\n",
    "i = 0\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    faces = face.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x, y, w, h) in faces:\n",
    "        #frame = cv.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        frame2 = frame[y:y + h, x:x + w]\n",
    "        #frame2 = escala(frame2,50)\n",
    "        frame2 = cv.resize(frame2, (100,100), interpolation=cv.INTER_AREA)\n",
    "        cv.imshow('frame', frame2)\n",
    "        cv.imwrite(\"E:/bd/dante/emociones/Triste/Triste\" + str(i) + \".png\", frame2)\n",
    "    cv.imshow('faces', frame)\n",
    "    i = i + 1\n",
    "    k = cv.waitKey(1)\n",
    "    if k == 27:\n",
    "        break\n",
    "cap.release()\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eigenface "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este código está utilizando la biblioteca OpenCV (importada como `cv`) para el reconocimiento facial. Primero, importa las bibliotecas necesarias: OpenCV, numpy y os.\n",
    "\n",
    "El código establece una ruta a un conjunto de datos de imágenes de caras con `dataSet = 'bd\\personas'`. Luego, utiliza `os.listdir(dataSet)` para obtener una lista de todos los archivos en ese directorio, que se asume que son imágenes de caras. Imprime esta lista de caras.\n",
    "\n",
    "Después, inicializa tres listas vacías: [`labels`](command:_github.copilot.openSymbolInFile?%5B%22c%3A%2FUsers%2Fdante%2FAppData%2FLocal%2FPrograms%2FPython%2FPython312%2FLib%2Fsite-packages%2Fcv2%2F__init__.pyi%22%2C%22labels%22%5D \"c:/Users/dante/AppData/Local/Programs/Python/Python312/Lib/site-packages/cv2/__init__.pyi\"), `facesData`, y `label`. [`labels`](command:_github.copilot.openSymbolInFile?%5B%22c%3A%2FUsers%2Fdante%2FAppData%2FLocal%2FPrograms%2FPython%2FPython312%2FLib%2Fsite-packages%2Fcv2%2F__init__.pyi%22%2C%22labels%22%5D \"c:/Users/dante/AppData/Local/Programs/Python/Python312/Lib/site-packages/cv2/__init__.pyi\") y `facesData` se llenarán con los datos de las imágenes y sus respectivas etiquetas. `label` es un contador que se incrementará para cada cara en el conjunto de datos.\n",
    "\n",
    "El código luego entra en un bucle for que recorre cada cara en la lista de caras. Para cada cara, crea una ruta al archivo de la imagen, luego abre esa imagen y la añade a la lista `facesData`. También añade la etiqueta actual a la lista [`labels`](command:_github.copilot.openSymbolInFile?%5B%22c%3A%2FUsers%2Fdante%2FAppData%2FLocal%2FPrograms%2FPython%2FPython312%2FLib%2Fsite-packages%2Fcv2%2F__init__.pyi%22%2C%22labels%22%5D \"c:/Users/dante/AppData/Local/Programs/Python/Python312/Lib/site-packages/cv2/__init__.pyi\"). Luego incrementa la etiqueta.\n",
    "\n",
    "Después de procesar todas las caras, imprime el número de etiquetas que son 0 utilizando [`np.count_nonzero(np.array(labels)==0)`](command:_github.copilot.openSymbolInFile?%5B%22c%3A%2FUsers%2Fdante%2FAppData%2FLocal%2FPrograms%2FPython%2FPython312%2FLib%2Fsite-packages%2Fnumpy%2Fcore%2Fnumeric.py%22%2C%22np.count_nonzero(np.array(labels)%3D%3D0)%22%5D \"c:/Users/dante/AppData/Local/Programs/Python/Python312/Lib/site-packages/numpy/core/numeric.py\"). Esto podría ser útil para saber cuántas imágenes pertenecen a la primera categoría.\n",
    "\n",
    "Finalmente, el código crea un objeto `EigenFaceRecognizer` utilizando `cv.face.EigenFaceRecognizer_create()`. Entrena este reconocedor con los datos de las caras y las etiquetas utilizando `faceRecognizer.train(facesData, np.array(labels))`. Luego guarda este reconocedor entrenado en un archivo llamado 'carasEigenface.xml' para su uso futuro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Felicidad', 'neutral', 'Sorpresa', 'Triste']\n",
      "2095\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv \n",
    "import numpy as np \n",
    "import os\n",
    "\n",
    "dataSet = \"E:/bd/emocionesv2\"\n",
    "faces  = os.listdir(dataSet)\n",
    "print(faces)\n",
    "\n",
    "labels = []\n",
    "facesData = []\n",
    "label = 0\n",
    "for face in faces:\n",
    "    facePath = dataSet+'\\\\'+face\n",
    "    for faceName in os.listdir(facePath):\n",
    "        labels.append(label)\n",
    "        facesData.append(cv.imread(facePath+'/'+faceName,0))\n",
    "    label = label + 1\n",
    "print(np.count_nonzero(np.array(labels)==0))\n",
    "\n",
    "faceRecognizer = cv.face.EigenFaceRecognizer_create()\n",
    "faceRecognizer.train(facesData, np.array(labels))\n",
    "faceRecognizer.write('emocionesEigenface.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este código en Python utiliza la biblioteca OpenCV (importada como `cv`) para detectar y reconocer rostros en tiempo real a través de la cámara del dispositivo.\n",
    "\n",
    "La función `detectar_rostros` primero define la ruta del conjunto de datos que contiene las imágenes de las caras en la variable `dataSet`. Luego, se obtiene una lista de todos los archivos en ese directorio utilizando `os.listdir(dataSet)` y se imprime.\n",
    "\n",
    "Se crea un objeto `EigenFaceRecognizer` utilizando `cv.face.EigenFaceRecognizer_create()`. Este objeto se utiliza para leer un modelo previamente entrenado de reconocimiento de rostros desde el archivo 'carasEigenface.xml'.\n",
    "\n",
    "Luego, se abre la cámara del dispositivo para capturar video en tiempo real y se inicializa un clasificador de cascada para la detección de rostros (`haarcascade_frontalface_alt.xml`).\n",
    "\n",
    "El código entra en un bucle infinito donde lee cada fotograma del video, lo convierte a escala de grises y luego utiliza el clasificador de cascada para detectar rostros en el fotograma. Para cada rostro detectado, se extrae la región del rostro del fotograma, se redimensiona a un tamaño fijo de 100x100 píxeles y luego se utiliza el reconocedor de rostros para predecir a quién pertenece el rostro.\n",
    "\n",
    "Si el resultado de la predicción tiene una confianza mayor a 2800, se considera que el rostro ha sido reconocido y se dibuja un rectángulo verde alrededor del rostro en el fotograma, y se coloca el nombre de la persona reconocida encima del rectángulo. Si la confianza es menor a 2800, se considera que el rostro es desconocido y se dibuja un rectángulo rojo alrededor del rostro, y se coloca la palabra 'Desconocido' encima del rectángulo.\n",
    "\n",
    "El bucle continúa hasta que se presiona la tecla 'Esc' (representada por el número 27). Al final, se libera el objeto de captura de video y se cierran todas las ventanas de imagen abiertas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Felicidad', 'neutral', 'Sorpresa', 'Triste']\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import os\n",
    "\n",
    "def detectar_rostros():\n",
    "\n",
    "    dataSet = \"E:/bd/emocionesv2\"\n",
    "    faces = os.listdir(dataSet)\n",
    "    print(faces)\n",
    "\n",
    "    faceRecognizer = cv.face.EigenFaceRecognizer_create()\n",
    "    faceRecognizer.read('emocionesEigenface.xml')\n",
    "\n",
    "    cap = cv.VideoCapture(0)\n",
    "    rostro = cv.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if ret == False:\n",
    "            break\n",
    "        gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "        cpGray = gray.copy()\n",
    "        rostros = rostro.detectMultiScale(gray, 1.3, 3)\n",
    "        for(x, y, w, h) in rostros:\n",
    "            frame2 = cpGray[y:y+h, x:x+w]\n",
    "            frame2 = cv.resize(frame2,  (100,100), interpolation=cv.INTER_CUBIC)\n",
    "            result = faceRecognizer.predict(frame2)\n",
    "            cv.putText(frame, '{}'.format(result), (x,y-20), 1,3.3, (255,255,0), 1, cv.LINE_AA)\n",
    "            if result[1] > 2800:\n",
    "                cv.putText(frame, '{}'.format(faces[result[0]]), (x,y-25), 2, 1.1, (0,255,0), 1, cv.LINE_AA)\n",
    "                cv.rectangle(frame, (x,y), (x+w,y+h), (0,255,0), 2)\n",
    "            else:\n",
    "                cv.putText(frame, 'Desconocido', (x,y-20), 2, 0.8, (0,0,255), 1, cv.LINE_AA)\n",
    "                cv.rectangle(frame, (x,y), (x+w,y+h), (0,0,255), 2)\n",
    "        cv.imshow('frame', frame)\n",
    "        k = cv.waitKey(1)\n",
    "        if k == 27:\n",
    "            break\n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()\n",
    "\n",
    "detectar_rostros()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fisherfaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este código utiliza la biblioteca OpenCV (importada como `cv`) para el reconocimiento facial. Primero, importa las bibliotecas necesarias: OpenCV, numpy y os.\n",
    "\n",
    "El código establece una ruta a un conjunto de datos de imágenes de caras con `dataSet = 'bd\\personas'`. Luego, utiliza `os.listdir(dataSet)` para obtener una lista de todos los archivos en ese directorio, que se asume que son imágenes de caras. Imprime esta lista de caras.\n",
    "\n",
    "Después, inicializa tres listas vacías: [`labels`](command:_github.copilot.openSymbolInFile?%5B%22c%3A%2FUsers%2Fdante%2FAppData%2FLocal%2FPrograms%2FPython%2FPython312%2FLib%2Fsite-packages%2Fcv2%2F__init__.pyi%22%2C%22labels%22%5D \"c:/Users/dante/AppData/Local/Programs/Python/Python312/Lib/site-packages/cv2/__init__.pyi\"), `facesData`, y `label`. [`labels`](command:_github.copilot.openSymbolInFile?%5B%22c%3A%2FUsers%2Fdante%2FAppData%2FLocal%2FPrograms%2FPython%2FPython312%2FLib%2Fsite-packages%2Fcv2%2F__init__.pyi%22%2C%22labels%22%5D \"c:/Users/dante/AppData/Local/Programs/Python/Python312/Lib/site-packages/cv2/__init__.pyi\") y `facesData` se llenarán con los datos de las imágenes y sus respectivas etiquetas. `label` es un contador que se incrementará para cada cara en el conjunto de datos.\n",
    "\n",
    "El código luego entra en un bucle for que recorre cada cara en la lista de caras. Para cada cara, crea una ruta al archivo de la imagen, luego abre esa imagen y la añade a la lista `facesData`. También añade la etiqueta actual a la lista [`labels`](command:_github.copilot.openSymbolInFile?%5B%22c%3A%2FUsers%2Fdante%2FAppData%2FLocal%2FPrograms%2FPython%2FPython312%2FLib%2Fsite-packages%2Fcv2%2F__init__.pyi%22%2C%22labels%22%5D \"c:/Users/dante/AppData/Local/Programs/Python/Python312/Lib/site-packages/cv2/__init__.pyi\"). Luego incrementa la etiqueta.\n",
    "\n",
    "Finalmente, el código crea un objeto `FisherFaceRecognizer` utilizando `cv.face.FisherFaceRecognizer_create()`. Entrena este reconocedor con los datos de las caras y las etiquetas utilizando `faceRecognizer.train(facesData, np.array(labels))`. Luego guarda este reconocedor entrenado en un archivo llamado 'carasFisherFace.xml' para su uso futuro. \n",
    "\n",
    "La diferencia principal entre este código y el anterior es que este utiliza el algoritmo FisherFace para el reconocimiento facial, mientras que el anterior utilizaba el algoritmo EigenFace. Ambos son métodos populares para el reconocimiento facial, pero pueden tener diferentes niveles de precisión y eficiencia dependiendo del conjunto de datos específico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Felicidad', 'neutral', 'Sorpresa', 'Triste']\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv \n",
    "import numpy as np \n",
    "import os\n",
    "\n",
    "dataSet = \"E:/bd/emociones\"\n",
    "faces  = os.listdir(dataSet)\n",
    "print(faces)\n",
    "\n",
    "labels = []\n",
    "facesData = []\n",
    "label = 0 \n",
    "for face in faces:\n",
    "    facePath = dataSet+'/'+face\n",
    "    for faceName in os.listdir(facePath):\n",
    "        labels.append(label)\n",
    "        facesData.append(cv.imread(facePath+'/'+faceName,0))\n",
    "    label = label + 1\n",
    "#print(np.count_nonzero(np.array(labels)==0)) \n",
    "faceRecognizer = cv.face.FisherFaceRecognizer_create()\n",
    "faceRecognizer.train(facesData, np.array(labels))\n",
    "faceRecognizer.write('emocionesFisherFace.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este código en Python utiliza la biblioteca OpenCV para implementar un sistema de reconocimiento facial en tiempo real a través de la cámara de la computadora.\n",
    "\n",
    "Primero, se crea un objeto `faceRecognizer` utilizando el método `FisherFaceRecognizer_create()` de OpenCV y se carga un modelo previamente entrenado desde el archivo 'laloFisherFace.xml' con el método [`read()`](command:_github.copilot.openSymbolInFile?%5B%22c%3A%2FUsers%2Fdante%2FAppData%2FLocal%2FPrograms%2FPython%2FPython312%2FLib%2Fsite-packages%2Fcv2%2F__init__.pyi%22%2C%22read()%22%5D \"c:/Users/dante/AppData/Local/Programs/Python/Python312/Lib/site-packages/cv2/__init__.pyi\").\n",
    "\n",
    "Luego, se inicia la captura de video desde la cámara predeterminada (índice 0) con `cv.VideoCapture(0)`. Se carga un clasificador preentrenado para detectar rostros frontales en una imagen con `cv.CascadeClassifier('data/haarcascade_frontalface_alt.xml')`.\n",
    "\n",
    "El código entra en un bucle infinito donde se captura un frame de la cámara con `cap.read()`. Si no se pudo leer el frame, se rompe el bucle. Luego, se convierte el frame a escala de grises con `cv.cvtColor(frame, cv.COLOR_BGR2GRAY)` y se guarda una copia de la imagen en escala de grises.\n",
    "\n",
    "Se detectan los rostros en la imagen en escala de grises con `rostro.detectMultiScale(gray, 1.3, 3)`. Para cada rostro detectado, se recorta la región del rostro, se redimensiona a un tamaño de 100x100 píxeles y se predice la identidad del rostro con `faceRecognizer.predict(frame2)`.\n",
    "\n",
    "El resultado de la predicción se dibuja en el frame original con `cv.putText()`. Si la confianza de la predicción es menor a 500, se considera que el rostro fue reconocido y se dibuja un rectángulo verde alrededor del rostro y se muestra el nombre de la persona reconocida. Si la confianza es mayor o igual a 500, se considera que el rostro es desconocido y se dibuja un rectángulo rojo alrededor del rostro y se muestra el texto 'Desconocido'.\n",
    "\n",
    "Finalmente, se muestra el frame con los rostros detectados y las predicciones con `cv.imshow('frame', frame)`. Si se presiona la tecla 'Esc', se rompe el bucle. Al final, se libera la captura de video y se cierran todas las ventanas de OpenCV.\n",
    "\n",
    "Nota: Hay un error en el código, se utiliza `cv2` en lugar de `cv` en varias líneas. Debería ser `cv.putText()` y `cv.rectangle()` en lugar de `cv2.putText()` y `cv2.rectangle()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['brenda', 'daniel', 'dante', 'jair', 'leo', 'martin']\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import os\n",
    "def detectar_rostros():\n",
    "\n",
    "    dataSet = \"E:/bd/emociones\"\n",
    "    faces = os.listdir(dataSet)\n",
    "    print(faces)\n",
    "\n",
    "    faceRecognizer = cv.face.FisherFaceRecognizer_create()\n",
    "    faceRecognizer.read('emocionesFisherFace.xml')\n",
    "\n",
    "    cap = cv.VideoCapture(0)\n",
    "    rostro = cv.CascadeClassifier('haarcascade_frontalface_alt2.xml')\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if ret == False: break\n",
    "        gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "        cpGray = gray.copy()\n",
    "        rostros = rostro.detectMultiScale(gray, 1.3, 3)\n",
    "        for(x, y, w, h) in rostros:\n",
    "            frame2 = cpGray[y:y+h, x:x+w]\n",
    "            frame2 = cv.resize(frame2,  (100,100), interpolation=cv.INTER_CUBIC)\n",
    "            result = faceRecognizer.predict(frame2)\n",
    "            cv.putText(frame, '{}'.format(result), (x,y-20), 1,3.3, (255,255,0), 1, cv.LINE_AA)\n",
    "            if result[1] < 500:\n",
    "                cv.rectangle(frame, (x,y),(x+w,y+h),(0,255,0),2)\n",
    "                cv.putText(frame, '{}'.format(faces[result[0]]), (x,y-25), 2, 1.1, (0,255,0), 1, cv.LINE_AA)\n",
    "            else:\n",
    "                cv.putText(frame,'Desconocido',(x,y-20),2,0.8,(0,0,255),1,cv.LINE_AA)\n",
    "                cv.rectangle(frame, (x,y),(x+w,y+h),(0,0,255),2)\n",
    "        cv.imshow('frame', frame)\n",
    "        k = cv.waitKey(1)\n",
    "        if k == 27:\n",
    "            break\n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()\n",
    "detectar_rostros()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LBPH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este código en Python utiliza la biblioteca OpenCV para entrenar un modelo de reconocimiento facial utilizando el algoritmo LBPH (Local Binary Patterns Histograms).\n",
    "\n",
    "Primero, se establece la ruta al conjunto de datos de imágenes de caras con `dataSet = 'bd\\personas'`. Luego, se utiliza `os.listdir(dataSet)` para obtener una lista de todos los archivos en ese directorio, que se asume que son imágenes de caras. Esta lista se imprime en la consola.\n",
    "\n",
    "Después, se inicializan tres listas vacías: [`labels`](command:_github.copilot.openSymbolInFile?%5B%22c%3A%2FUsers%2Fdante%2FAppData%2FLocal%2FPrograms%2FPython%2FPython312%2FLib%2Fsite-packages%2Fcv2%2F__init__.pyi%22%2C%22labels%22%5D \"c:/Users/dante/AppData/Local/Programs/Python/Python312/Lib/site-packages/cv2/__init__.pyi\"), `facesData` y `label`. [`labels`](command:_github.copilot.openSymbolInFile?%5B%22c%3A%2FUsers%2Fdante%2FAppData%2FLocal%2FPrograms%2FPython%2FPython312%2FLib%2Fsite-packages%2Fcv2%2F__init__.pyi%22%2C%22labels%22%5D \"c:/Users/dante/AppData/Local/Programs/Python/Python312/Lib/site-packages/cv2/__init__.pyi\") y `facesData` se llenarán con los datos de las imágenes y sus respectivas etiquetas. `label` es un contador que se incrementará para cada cara en el conjunto de datos.\n",
    "\n",
    "El código luego entra en un bucle for que recorre cada cara en la lista de caras. Para cada cara, crea una ruta al archivo de la imagen, luego abre esa imagen y la añade a la lista `facesData`. También añade la etiqueta actual a la lista [`labels`](command:_github.copilot.openSymbolInFile?%5B%22c%3A%2FUsers%2Fdante%2FAppData%2FLocal%2FPrograms%2FPython%2FPython312%2FLib%2Fsite-packages%2Fcv2%2F__init__.pyi%22%2C%22labels%22%5D \"c:/Users/dante/AppData/Local/Programs/Python/Python312/Lib/site-packages/cv2/__init__.pyi\"). Luego incrementa la etiqueta.\n",
    "\n",
    "Finalmente, el código crea un objeto `LBPHFaceRecognizer` utilizando `cv.face.LBPHFaceRecognizer_create()`. Entrena este reconocedor con los datos de las caras y las etiquetas utilizando `faceRecognizer.train(facesData, np.array(labels))`. Luego guarda este reconocedor entrenado en un archivo llamado 'carasLBPHFace.xml' para su uso futuro.\n",
    "\n",
    "El algoritmo LBPH es un método popular para el reconocimiento facial que puede ser más eficiente y preciso que otros métodos para ciertos conjuntos de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:5: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\p'\n",
      "C:\\Users\\dante\\AppData\\Local\\Temp\\ipykernel_16828\\165381371.py:5: SyntaxWarning: invalid escape sequence '\\p'\n",
      "  dataSet = 'bd\\personas'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['brenda', 'daniel', 'dante', 'jair', 'leo', 'martin']\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv \n",
    "import numpy as np \n",
    "import os\n",
    "\n",
    "dataSet = \"E:/bd/emociones\"\n",
    "faces  = os.listdir(dataSet)\n",
    "print(faces)\n",
    "\n",
    "labels = []\n",
    "facesData = []\n",
    "label = 0 \n",
    "for face in faces:\n",
    "    facePath = dataSet+'/'+face\n",
    "    for faceName in os.listdir(facePath):\n",
    "        labels.append(label)\n",
    "        facesData.append(cv.imread(facePath+'/'+faceName,0))\n",
    "    label = label + 1\n",
    "#print(np.count_nonzero(np.array(labels)==0)) \n",
    "faceRecognizer = cv.face.LBPHFaceRecognizer_create()\n",
    "faceRecognizer.train(facesData, np.array(labels))\n",
    "faceRecognizer.write('emocionesLBPHFace.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este código es un ejemplo de reconocimiento facial utilizando la biblioteca OpenCV en Python. Aquí está lo que hace cada parte del código:\n",
    "\n",
    "1. Importa las bibliotecas necesarias: `cv2` para el procesamiento de imágenes y `os` para las operaciones del sistema operativo. Sin embargo, parece que `os` no se utiliza en este código.\n",
    "\n",
    "2. Crea un objeto `faceRecognizer` utilizando el método `LBPHFaceRecognizer_create()`. Este objeto se utiliza para reconocer caras en las imágenes.\n",
    "\n",
    "3. Lee un archivo XML que contiene el modelo de reconocimiento facial entrenado.\n",
    "\n",
    "4. Abre la cámara del dispositivo (indicado por el `0` en `cv.VideoCapture(0)`) para capturar video en tiempo real.\n",
    "\n",
    "5. Carga el clasificador de rostros Haar Cascade desde un archivo XML.\n",
    "\n",
    "6. Entra en un bucle infinito donde captura cada frame del video, lo convierte a escala de grises y detecta rostros en él.\n",
    "\n",
    "7. Para cada rostro detectado, se extrae la región de interés, se redimensiona a un tamaño estándar de 100x100 píxeles y se pasa al reconocedor de caras para obtener una predicción.\n",
    "\n",
    "8. La predicción y la confianza se dibujan en el frame original. Si la confianza es menor que 70, se considera que el rostro es reconocido y se dibuja un rectángulo verde alrededor del rostro. Si no, se considera desconocido y se dibuja un rectángulo rojo.\n",
    "\n",
    "9. Muestra el frame con las anotaciones en una ventana.\n",
    "\n",
    "10. Si se presiona la tecla `ESC` (27 en código ASCII), se rompe el bucle.\n",
    "\n",
    "11. Al final, libera el objeto de captura de video y cierra todas las ventanas de OpenCV.\n",
    "\n",
    "El error \"cv2 no está definido\" sugiere que estás intentando utilizar la biblioteca `cv2` pero la has importado como `cv`. Deberías cambiar todas las referencias de `cv2` a `cv` en tu código. Además, parece que la variable [`faces`](command:_github.copilot.openSymbolInFile?%5B%22c%3A%2FUsers%2Fdante%2FAppData%2FLocal%2FPrograms%2FPython%2FPython312%2FLib%2Fsite-packages%2Fcv2%2F__init__.pyi%22%2C%22faces%22%5D \"c:/Users/dante/AppData/Local/Programs/Python/Python312/Lib/site-packages/cv2/__init__.pyi\") no está definida en este fragmento de código. Necesitarías definirlo o importarlo de algún lugar antes de usarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['brenda', 'daniel', 'dante', 'jair', 'leo', 'martin']\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import os\n",
    "\n",
    "def detectar_rostros():\n",
    "\n",
    "    dataSet = \"E:/bd/emociones\"\n",
    "    faces = os.listdir(dataSet)\n",
    "    print(faces)\n",
    "\n",
    "    faceRecognizer = cv.face.LBPHFaceRecognizer_create()\n",
    "    faceRecognizer.read('emocionesLBPHFace.xml')\n",
    "\n",
    "    cap = cv.VideoCapture(0)\n",
    "    rostro = cv.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if ret == False: break\n",
    "        gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "        cpGray = gray.copy()\n",
    "        rostros = rostro.detectMultiScale(gray, 1.3, 3)\n",
    "        for(x, y, w, h) in rostros:\n",
    "            frame2 = cpGray[y:y+h, x:x+w]\n",
    "            frame2 = cv.resize(frame2,  (100,100), interpolation=cv.INTER_CUBIC)\n",
    "            result = faceRecognizer.predict(frame2)\n",
    "            cv.putText(frame, '{}'.format(result), (x,y-20), 1,3.3, (255,255,0), 1, cv.LINE_AA)\n",
    "            if result[1] < 70:\n",
    "                cv.putText(frame,'{}'.format(faces[result[0]]),(x,y-25),2,1.1,(0,255,0),1,cv.LINE_AA)\n",
    "                cv.rectangle(frame, (x,y),(x+w,y+h),(0,255,0),2)\n",
    "            else:\n",
    "                cv.putText(frame,'Desconocido',(x,y-20),2,0.8,(0,0,255),1,cv.LINE_AA)\n",
    "                cv.rectangle(frame, (x,y),(x+w,y+h),(0,0,255),2)\n",
    "        cv.imshow('frame', frame)\n",
    "        k = cv.waitKey(1)\n",
    "        if k == 27:\n",
    "            break\n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()\n",
    "detectar_rostros()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
